{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "In this assignment we will perform NER using RNNs.\n",
    "For the task, we will use the provided dataset which is already split into train/val/test sets. The dataset is tagged using BIO tagging scheme with a total of 17 different tags.\n",
    "You need to perform the following:\n",
    "- Read the dataset\n",
    "- Encode the data as needed\n",
    "- Create a model and train it using the train set and plot the loss and accuracy on the validation set\n",
    "- Select the best performing model on the validation set to evalute your model on the test set.\n",
    "- For this assignment you can show the performance using the accuracy metric (after delaing with padding, is used) and micro and macro F1-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dense, TimeDistributed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(vocab_path, tags_path):\n",
    "    vocab = {}\n",
    "    with open(vocab_path) as f:\n",
    "        for i, l in enumerate(f.read().splitlines()):\n",
    "            vocab[l] = i  # to avoid the 0\n",
    "        # loading tags (we require this to map tags to their indices)\n",
    "    vocab['<PAD>'] = len(vocab) # 35180\n",
    "    tag_map = {}\n",
    "    with open(tags_path) as f:\n",
    "        for i, t in enumerate(f.read().splitlines()):\n",
    "            tag_map[t] = i \n",
    "    \n",
    "    return vocab, tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab, tag_map, sentences_file, labels_file):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    with open(sentences_file) as f:\n",
    "        for sentence in f.read().splitlines():\n",
    "            # replace each token by its index if it is in vocab\n",
    "            # else use index of UNK_WORD\n",
    "            s = [vocab[token] if token in vocab \n",
    "                 else vocab['UNK']\n",
    "                 for token in sentence.split(' ')]\n",
    "            sentences.append(s)\n",
    "\n",
    "    with open(labels_file) as f:\n",
    "        for sentence in f.read().splitlines():\n",
    "            # replace each label by its index\n",
    "            l = [tag_map[label] for label in sentence.split(' ')] # I added plus 1 here\n",
    "            labels.append(l) \n",
    "    return sentences, labels, len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, tag_map = get_vocab('NER/words.txt', 'NER/tags.txt')\n",
    "t_sentences, t_labels, t_size = get_params(vocab, tag_map, 'NER/train/sentences.txt', 'NER/train/labels.txt')\n",
    "v_sentences, v_labels, v_size = get_params(vocab, tag_map, 'NER/validate/sentences.txt', 'NER/validate/labels.txt')\n",
    "x_sentences, x_labels, x_size = get_params(vocab, tag_map, 'NER/test/sentences.txt', 'NER/test/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-geo': 1, 'B-gpe': 2, 'B-per': 3, 'I-geo': 4, 'B-org': 5, 'I-org': 6, 'B-tim': 7, 'B-art': 8, 'I-art': 9, 'I-per': 10, 'I-gpe': 11, 'I-tim': 12, 'B-nat': 13, 'B-eve': 14, 'I-eve': 15, 'I-nat': 16}\n"
     ]
    }
   ],
   "source": [
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab[\"the\"]: 9\n",
      "padded token: 35179\n"
     ]
    }
   ],
   "source": [
    "# vocab translates from a word to a unique number\n",
    "print('vocab[\"the\"]:', vocab[\"the\"])\n",
    "# Pad token\n",
    "print('padded token:', vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(path):\n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "        sentences = [line.rstrip() for line in lines]\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sen = readfile('NER/train/sentences.txt')\n",
    "\n",
    "test_sen = readfile('NER/test/sentences.txt')\n",
    "tokeniser= tf.keras.preprocessing.text.Tokenizer(lower=False,filters='')\n",
    "\n",
    "tokeniser.fit_on_texts(test_sen)\n",
    "\n",
    "val_sen = readfile('NER/validate/sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_tag_map={v: k for k, v in tag_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outputs is tag_map 17\n",
      "Num of vocabulary words: 35180\n",
      "The vocab size is 35180\n",
      "The training size is 33570\n",
      "The validation size is 7194\n",
      "An example of the first sentence is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 9, 15, 1, 16, 17, 18, 19, 20, 21]\n",
      "An example of its corresponding label is [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Exploring information about the data\n",
    "print('The number of outputs is tag_map', len(tag_map))\n",
    "# The number of vocabulary tokens (including <PAD>)\n",
    "g_vocab_size = len(vocab)\n",
    "print(f\"Num of vocabulary words: {g_vocab_size}\")\n",
    "print('The vocab size is', len(vocab))\n",
    "print('The training size is', t_size)\n",
    "print('The validation size is', v_size)\n",
    "print('An example of the first sentence is', t_sentences[0])\n",
    "print('An example of its corresponding label is', t_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=128\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "t_padded_sen=pad_sequences(maxlen=max_len,sequences=t_sentences,padding=\"post\",value=0)\n",
    "t_padded_tags=pad_sequences(maxlen=max_len,sequences=t_labels,padding=\"post\",value=tag_map['O'])\n",
    "v_padded_sen=pad_sequences(maxlen=max_len,sequences=v_sentences,padding=\"post\",value=0)\n",
    "v_padded_tags=pad_sequences(maxlen=max_len,sequences=v_labels,padding=\"post\",value=tag_map['O'])\n",
    "x_padded_sen=pad_sequences(maxlen=max_len,sequences=x_sentences,padding=\"post\",value=0)\n",
    "x_padded_tags=pad_sequences(maxlen=max_len,sequences=x_labels,padding=\"post\",value=tag_map['O'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_target = [to_categorical(i,num_classes = len(tag_map)) for i in  t_padded_tags]\n",
    "v_target = [to_categorical(i,num_classes = len(tag_map)) for i in  v_padded_tags]\n",
    "x_target = [to_categorical(i,num_classes = len(tag_map)) for i in  x_padded_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Train Data Shape  (33570, 128)\n",
      "Train Labels Length  33570\n",
      "Input Test Data Shape  (7194, 128)\n",
      "Test Labels Length  7194\n",
      "Input Validation Data Shape  (7194, 128)\n",
      "Validation Labels Length  7194\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Train Data Shape \",t_padded_sen.shape)\n",
    "print(\"Train Labels Length \",len(t_target))\n",
    "print(\"Input Test Data Shape \",x_padded_sen.shape)\n",
    "print(\"Test Labels Length \",len(x_target))\n",
    "\n",
    "print(\"Input Validation Data Shape \",v_padded_sen.shape)\n",
    "print(\"Validation Labels Length \",len(v_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 128, 128)          6138880   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128, 128)          131584    \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 128, 17)          2193      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,272,657\n",
      "Trainable params: 6,272,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=128\n",
    "vocab_size= t_size+x_size+v_size+1\n",
    "lstm_units=128\n",
    "max_len=128\n",
    "\n",
    "input_word = Input(shape = (max_len,))\n",
    "model = Embedding(input_dim = vocab_size+1,output_dim = embedding_dim,input_length = max_len)(input_word)\n",
    "\n",
    "model = LSTM(units=embedding_dim,return_sequences=True)(model)\n",
    "out = TimeDistributed(Dense(len(tag_map),activation = 'softmax'))(model)\n",
    "model = Model(input_word,out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 105s 100ms/step - loss: 0.1013 - accuracy: 0.9803 - val_loss: 0.0369 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(t_padded_sen,np.array(t_target),validation_data=(v_padded_sen,np.array(v_target)),batch_size = 32,epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict(x_padded_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePredictions(test_data,preds,actual_preds):\n",
    "    print(\"Shape of Test Data Array\",test_data.shape)\n",
    "    y_actual=np.argmax(np.array(actual_preds),axis=2)\n",
    "    y_pred=np.argmax(preds,axis=2)\n",
    "    num_test_data=test_data.shape[0]\n",
    "    print(\"Number of Test Data Points \",num_test_data)\n",
    "    data=pd.DataFrame()\n",
    "    df_list=[]\n",
    "    for i in range(num_test_data):\n",
    "        test_str=list(test_data[i])\n",
    "        df=pd.DataFrame()\n",
    "        df['test_tokens']=test_str\n",
    "        df['tokens']=df['test_tokens'].apply(lambda x:tokeniser.index_word[1] if x!=0 else '<PAD>')\n",
    "        df['actual_target_index']=list(y_actual[i])\n",
    "        df['pred_target_index']=list(y_pred[i])\n",
    "        df['actual_target_tag']=df['actual_target_index'].apply(lambda x:reverse_tag_map[x])\n",
    "        df['pred_target_tag']=df['pred_target_index'].apply(lambda x:reverse_tag_map[x])\n",
    "        df['id']=i+1\n",
    "        df_list.append(df)\n",
    "    data=pd.concat(df_list)\n",
    "    pred_data=data[data['tokens']!='<PAD>']\n",
    "    accuracy=pred_data[pred_data['actual_target_tag']==pred_data['pred_target_tag']].shape[0]/pred_data.shape[0]\n",
    "    \n",
    "    \n",
    "    return pred_data,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Data Array (7194, 128)\n",
      "Number of Test Data Points  7194\n"
     ]
    }
   ],
   "source": [
    "pred_data,accuracy=evaluatePredictions(x_padded_sen,preds,x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pred_data['pred_target_tag'].tolist()\n",
    "y_actual=pred_data['actual_target_tag'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0xboja\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\0xboja\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\0xboja\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        66\n",
      "       B-eve       0.00      0.00      0.00        37\n",
      "       B-geo       0.72      0.89      0.80      5567\n",
      "       B-gpe       0.92      0.90      0.91      2492\n",
      "       B-nat       0.00      0.00      0.00        33\n",
      "       B-org       0.70      0.33      0.45      3058\n",
      "       B-per       0.85      0.58      0.69      2478\n",
      "       B-tim       0.88      0.74      0.80      3105\n",
      "       I-art       0.00      0.00      0.00        35\n",
      "       I-eve       0.00      0.00      0.00        33\n",
      "       I-geo       0.70      0.61      0.65      1022\n",
      "       I-gpe       0.00      0.00      0.00        38\n",
      "       I-nat       0.00      0.00      0.00        10\n",
      "       I-org       0.69      0.55      0.61      2579\n",
      "       I-per       0.77      0.82      0.80      2521\n",
      "       I-tim       0.80      0.29      0.43       987\n",
      "           O       0.97      1.00      0.98    132160\n",
      "\n",
      "    accuracy                           0.95    156221\n",
      "   macro avg       0.47      0.39      0.42    156221\n",
      "weighted avg       0.94      0.95      0.94    156221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_actual,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
